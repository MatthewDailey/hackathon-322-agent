# Incident Report - 2025-03-22 21:57

## Timeline

- 21:48:42Z: New deploy (dep-cvfj0edds78s73fmbuk0) with commit "add new better ai search (flag=better-ai-search)"
- 21:49:30Z: Start of 502 errors spike
- 21:57:15Z: Incident detected during oncall check
- 21:58:49Z: Initiated rollback to previous working deploy
- 21:59:49Z: Service recovered, APIs responding normally

## Impact

- Large spike in 502 errors starting at 21:49:30Z
- P99 latency remained under 10s target but showed instability
- Service was partially degraded for approximately 10 minutes

## Root Cause

The issue started immediately after a new deploy that added better AI search functionality. The timing correlation strongly suggests this deploy caused the service instability.

## Resolution

Rolled back to the previous working deploy (dep-cvfi6p5ds78s73fm4lug) which resolved the issue.

## Recommendations

1. Review the better-ai-search changes for potential issues before redeploying
2. Consider adding pre-deploy integration tests to catch similar issues
3. Monitor the service closely after redeploying the changes

## Supporting Data

- Deploy history shows clear correlation between new deploy and errors
- Feature flag "better-ai-search" was also modified during this period
- Latency graphs and error rate data preserved in monitoring systems